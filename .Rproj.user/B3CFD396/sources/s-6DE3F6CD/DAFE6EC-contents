---
title: "Credit Score Card"
output: html_notebook
---

Load functions and libraries
```{r}
source("../code/helper_functions.R")
LoadPackages(c("dplyr", "smbinning", "stringr", "ggplot2", "forcats",
                "tibble", "gmodels", "vcd", "caret", "gridExtra", "tidyr"))
select <- dplyr::select
```

Read in data
```{r}
rejects2 <- readRDS("../data/rejects_v2.rds")
accepts2 <- readRDS("../data/accepts_v2.rds")
train <- readRDS("../data/train.rds")
test <- readRDS("../data/test.rds")
```

Create variable "good" bc smbinning expects it
```{r}
train$good = abs(as.numeric(train$GB) - 2)
train <- train %>% select(GB, good, everything())
test$good = abs(as.numeric(test$GB) - 2)
test <- test %>% select(GB, good, everything(), -id)
```

Bin variables into categories and calculate WOE values
```{r}
# col names of numeric predictor variables
num_names <- names(train )[sapply(train, is.numeric)]
num_names <- num_names[3:length(num_names)]

sm_result1 <- sig_bins(df = train, 
                       col_names = num_names, 
                       numeric = T, 
                       good_col = "good")

# col names of factor predictor variables
factor_names <- names(train)[sapply(train, is.factor)]
factor_names <- factor_names[2:length(factor_names)]

sm_result2 <- sig_bins(df = train, 
                       col_names = factor_names, 
                       numeric = F, 
                       good_col = "good")
```

Create binned variables for train and test set
```{r}
# numeric variables bins
train <- bin_cols(sm_result1, df = train, numeric = T)
# factor varialbes bins
train <- bin_cols(sm_result2, df = train, numeric = F)

# test set: numeric variables bins
test <- bin_cols(sm_result1, df = test, numeric = T)
# test set: factor varialbes bins
test <- bin_cols(sm_result2, df =test, numeric = F)
```

Generate variables for WOE values
```{r}
# train set: woe values for numeric variables
train <- gen_woe(sm_result1, df = train)
# train set: woe values for factor varialbes
train <- gen_woe(sm_result2, df = train)

# test set woe values for numeric variables
test <- gen_woe(sm_result1, df = test)
# test set: woe values for factor varialbes
test <- gen_woe(sm_result2, df = test)
```

Train logistic model with the signifigant WOE variables
```{r}
train2 <- train %>% select(GB, `_freq_`, ends_with("WOE"))
train2 <- train2 %>% select(GB, 
                            `_freq_`, 
                            AGE_WOE, 
                            TMJOB1_WOE, 
                            income_cash_ratio_WOE,
                            CARDS_WOE, adult_WOE )

# create log regression model
score_card1 <- glm(data = train2, GB ~ . -`_freq_`,
                   weights = train$`_freq_`, 
                   family = "binomial",
                   control = list(maxit = 100))

# coefs, pvalues etc of model
summary(score_card1)
```

Evaluate performance of model on test set
```{r}
# predict on test set (used by smbinnin.metrics)
test$pred <- predict(score_card1, newdata=test, type='response')
# cast as numeric (bc smbinning needs numeric)
test$GB <- as.character(test$GB) %>% as.numeric()
# model performance on test set
smbinning.metrics(dataset = test, prediction = "pred", 
                  actualclass = "GB", report = 1)
```


Created binned variables for rejects and accepts set
```{r}
# numeric variables bins
rejects_scored <- bin_cols(sm_result1, df = rejects2, numeric = T)
# factor varialbes bins
rejects_scored <- bin_cols(sm_result2, df = rejects_scored, numeric = F)


```

Generate WOE values for rejects and accepts set
```{r}
# woe values for numeric variables
rejects_scored <- gen_woe(sm_result1, df = rejects_scored)
# woe values for factor varialbes
rejects_scored <- gen_woe(sm_result2, df = rejects_scored)


```

Generate scores for the rejects set and accepts set
```{r}

```





```{r}
# # predict prob on reject set
# rejects_scored$pred <- predict(score_card1, newdata=rejects_scored, 
#                                type='response')
# # label 1 or 0 based on optimum cutoff from smbinnimg report
# rejects2$GB <- as.numeric(rejects_scored$pred > 0.0286)
# # add weights based of 75% acceptance rate and 30:1 odds for bad:good
# rejects2$`_freq_` <- ifelse(rejects2$GB == 1, 1, 30)
# # addjust weights for accepts set so it's proportional to rejects
# accepts2$`_freq_` <- accepts2$`_freq_` * 3
# # combine the accepts and rejects sets
# comb <- rbind(accepts2, rejects2) 
```

Split the combined set to train and test
```{r}
set.seed(8888)
train_id <- createDataPartition(y = comb_parc$`_freq`, p = .7, list = F)

train_comb <- comb_parc[train_id, ]
test_comb <- comb_parc[-train_id, ] 

# create good variable and reorder cols (smbin needs same order and good var)
test_comb$good <- abs(as.numeric(test_comb$GB) - 2)
test_comb <- test_comb %>% select(GB, `_freq_`, good, everything())
train_comb$good <- abs(as.numeric(train_comb$GB) - 2)
train_comb <- train_comb %>% select(GB, `_freq_`, good, everything()) 
```

Bin variables into categories and calculate WOE values based on train_comb set
```{r}
# col names of numeric predictor variables
num_names <- names(train_comb )[sapply(train_comb, is.numeric)]
num_names <- num_names[4:length(num_names)]

sm_result3 <- sig_bins(df = train_comb, 
                       col_names = num_names, 
                       numeric = T, 
                       good_col = "good")

# col names of factor predictor variables
factor_names <- names(train_comb)[sapply(train_comb, is.factor)]
factor_names <- factor_names[2:length(factor_names)]

sm_result4 <- sig_bins(df = train_comb, 
                       col_names = factor_names, 
                       numeric = F, 
                       good_col = "good")
```

Train set: Create binned variables and WOE values
```{r}
# numeric variables bins
train_comb <- bin_cols(sm_result3, df = train_comb, numeric = T)
# factor varialbes bins
train_comb <- bin_cols(sm_result4, df = train_comb, numeric = F)

# woe values for numeric variables
train_comb <- gen_woe(sm_result3, df = train_comb)
# woe values for factor varialbes
train_comb <- gen_woe(sm_result4, df = train_comb)
```

Adjust bands to test set
```{r}
for(i in names(sm_result3)) {
  sm_result3[[i]]$bands[1] <- min(test_comb[[i]], na.rm = TRUE)
  sm_result3[[i]]$bands[length(sm_result3[[i]]$bands)] <- max(test_comb[[i]], 
                                                                na.rm = TRUE)
}
```

Test set: Create binned variables and generate variables WOE values
```{r}
# add a copy of obs with motorbike from train set into test set
# bc test set doesn't have one and caused error with smbinning gen
# should have one hot encodedeverything from the start
dupe_obs <- train_comb %>% filter(CAR == 'Motorbike') %>% slice(1)
test_comb <- bind_rows(test_comb, dupe_obs %>% select(names(test_comb)))

# numeric variables bins
test_comb <- bin_cols(sm_result3, df = test_comb, numeric = T)
# factor varialbes bins
test_comb <- bin_cols(sm_result4, df = test_comb, numeric = F)

# woe values for numeric variables
test_comb <- gen_woe(sm_result3, df = test_comb)
# woe values for factor varialbes
test_comb <- gen_woe(sm_result4, df = test_comb)
```

Train logistic model with the signifigant WOE variables
```{r}
train_comb2 <- train_comb %>% select(GB, `_freq_`, ends_with('WOE')) %>%
  select(  -STATUS_WOE, 
           -income_per_pers_WOE, -EC_CARD_WOE, -PERS_H_WOE )


score_card2 <- glm(data = train_comb2, GB ~ . -`_freq_`,
                   weights = train_comb$`_freq_`, 
                   family = "binomial",
                   control = list(maxit = 100))

summary(score_card2)
```

Evaluate performance of model on test set
```{r}
# predict on test set
test_comb$pred <- predict(score_card2, newdata=test_comb, type='response')
# cast as numeric (bc smbinning needs numeric)
test_comb$GB <- as.character(test_comb$GB) %>% as.numeric()
# model performance on test set
smbinning.metrics(dataset = test_comb, prediction = "pred", 
                  actualclass = "GB", report = 1)
```

Combine train and test set
```{r}
train_comb$set <- "train"
train_comb$GB <- as.character(train_comb$GB) %>% as.numeric()
test_comb$set <- "test"

all_scored <- bind_rows(train_comb, test_comb %>% 
                          select(names(train_comb))) %>%
  as.data.frame()
```

Generate scores, buckets for the scores and predicted probabilities
```{r}
# generate a score for each person
all_scored <- allocate_points(mod = score_card2, df = all_scored,
                              pdo = 50, score = 500, odds = 20)

# create buckets / categories for the scores 
all_scored$buckets <- cut(all_scored$Score, breaks = c(seq(300, 750, 50)))

# create predicted probabilities for each person
all_scored$pred <- predict(score_card2, newdata=all_scored, type='response')
```

Create the acutal score card
```{r}
# create vector of the bin variable names
bin_cols <- score_card2$coefficients[-1] %>% 
  names %>% 
  str_replace_all("_WOE", "_bin")

# create vector of the points variable names
points_cols <- score_card2$coefficients[-1] %>% 
  names %>% 
  str_replace_all("_WOE", "_points")

# create data frame with just the bin and points columns
score_card_cols <- all_scored %>% select(bin_cols, points_cols)

# create a list of DFs where each df has the bin and points associated with it
# for each predictor
score_list <- list()
for(i in 1:length(bin_cols)) {
  # DF for bins and points associated w/ it for each predictor
  score_card_temp <- score_card_cols %>% 
    select(i, i+length(bin_cols)) %>% 
    distinct() 

  score_card_temp$var <- names(score_card_temp)[1]
  names(score_card_temp) <- c('bin', 'points', 'var')
  score_card_temp$bin <- as.character(score_card_temp$bin)
  score_card_temp <- score_card_temp %>% arrange(bin)
  score_list[[i]] <- score_card_temp
}

score_card <- do.call(bind_rows, score_list) %>% mutate(points = round(points))

#write.csv(score_card, "../data/score_card.csv")
```

Adjust observations for the weights
```{r}
# duplicate rows based on the freq / weight column so that it's a representative
# sample of applicants
scored_adj <- all_scored[rep(seq_along(all_scored$`_freq_`), 
                             all_scored$`_freq_`), ]
```


Average predicted probability and bad rate for each score bucket
```{r}
# average prob for each score bucket
score_bucket <- scored_adj %>% 
  group_by(buckets) %>% 
  summarize("Avg Probability" = mean(pred), count = n(), 
            bad_n = sum(GB) , "Default Rate" = bad_n / count) %>%
  mutate(buckets = str_replace_all(buckets,",", ", ")) %>%
  select(buckets, "Avg Probability", "Default Rate") %>% 
  gather(key, value, -buckets)
```

Bar charts of default probability and rate by score
```{r}
ggplot(score_bucket, aes(x = fct_rev(buckets), y = value, fill = factor(key))) +
  geom_col(stat = "identity", position = "dodge") +
  coord_flip() +
  labs(title = "Default Probability & Rate ",
       x = "Score",
       y = "Default Probability / Rate") +
  theme_bw() +
  theme(plot.title = element_text(hjust = .5, size = 22, face = "bold"),
        axis.text=element_text(size=13),
        axis.title=element_text(size=18),
        axis.line = element_line(colour = "black"),
        legend.text=element_text(size=12),
        legend.title = element_blank(),
        legend.position = c(.8,.15)) 
```

Picking a cut off score
```{r}
# use test set for picking cut off score
# already adjusted for weights
test_scored <- scored_adj %>% filter(set == "test")

# number of accepts, bads, and goods for scores over 400
accepts_n <- c(test_scored %>% filter(Score > 400) %>% nrow())
bad_n <- c(test_scored %>% filter(Score > 400 & GB ==1) %>% nrow())
good_n <- c(test_scored %>% filter(Score > 400 & GB ==0) %>% nrow())

# scores 401 to 600 find the number of accepts, bads and goods
for(cut in 401:600){
 num_accept <- test_scored %>% filter(Score > cut) %>% nrow()
 accepts_n <- c(accepts_n, num_accept)
 
 num_bad <- test_scored %>% filter(Score > cut & GB ==1) %>% nrow()
 bad_n <- c(bad_n, num_bad)
 
 num_good <- test_scored %>% filter(Score > cut & GB ==0) %>% nrow()
 good_n <- c(good_n, num_good)

}

# create df with the number of accepts, bads, and goods for each cutoff point
cutoffs <- data.frame('cutoff' = 400:600, 
                      'accepts_n' = accepts_n,
                      "bad_n" = bad_n,
                      "good_n" = good_n) %>%
  mutate(total_n = nrow(test_scored),
         accepts_per = (accepts_n / total_n) *100, # percentage of accepts
         bad_per = (bad_n / accepts_n) *100, # percentage of accepts that are bad
         good_rev = 2000 * good_n, # revenye from goods
         bad_cost = -52000 * bad_n, # costs from bads
         profit = good_rev + bad_cost,
         profit_per_cust = profit / (nrow(test_scored)))

# optimal cut off to max profit
max_profit <- max(cutoffs$profit_per_cust)
opt_cut <- cutoffs %>% filter(profit_per_cust == max_profit) %>% pull(cutoff)
# acceptance % for optimal cut
opt_acpt <- cutoffs %>% filter(profit_per_cust == max_profit) %>% 
  pull(accepts_per)
# bad % for optimal cut
opt_bad <- cutoffs %>% filter(profit_per_cust == max_profit) %>% 
  pull(bad_per)
```

```{r}
ggplot(cutoffs, aes(x= cutoff, y = profit_per_cust)) + 
  geom_line(size = 1.5, color = "seagreen") +
  geom_hline(yintercept = max_profit, color = 'red') +
  geom_vline(xintercept = opt_cut, color = 'red') +
  labs(title = "Cutoff Score: Profit",
       x = "Cutoff Score",
       y = "Profit Per Customer ($)") +
  theme_bw() +
  theme(plot.title = element_text(hjust = .5, size = 22, face = "bold"),
        axis.text=element_text(size=13),
        axis.title=element_text(size=18),
        axis.line = element_line(colour = "black")) +
  scale_x_continuous( breaks = c(seq(400,600, 25))) +
  scale_y_continuous( breaks = c(seq(200,800, 100)))
```

```{r}
p1 <- ggplot(cutoffs, aes(x= cutoff, y = accepts_per)) + 
  geom_line(size = 1.5, color = "olivedrab2") +
  coord_flip() +
  geom_hline(yintercept = opt_acpt, color = 'red') +
  labs(x = "",
       y = "Acceptance %") +
  theme_bw() +
  theme(plot.title = element_text(hjust = .5, size = 22, face = "bold"),
        axis.text=element_text(size=13),
        axis.title=element_text(size=18),
        axis.line = element_line(colour = "black")) +
  scale_x_continuous( breaks = c(seq(400,600, 50))) +
  scale_y_continuous( breaks = c(seq(25,100, 10)))

p2 <- ggplot(cutoffs, aes(x= cutoff, y = bad_per)) + 
  geom_line(size = 1.5, color = "tomato4") +
  coord_flip() +
  geom_hline(yintercept = opt_bad, color = 'red') +
  labs(x = "",
       y = "Default %") +
  theme_bw() +
  theme(plot.title = element_text(hjust = .5, size = 22, face = "bold"),
        axis.text=element_text(size=13),
        axis.title=element_text(size=18),
        axis.line = element_line(colour = "black"))+
  scale_x_continuous( breaks = c(seq(400,600, 50))) +
  scale_y_continuous( breaks = c(seq(0,3.25, .25)))

grid.arrange(p1, p2, ncol = 1)
```
        
Confusion Matrix for unadjusted test set using score cutoff
```{r}
test_scored2 <- all_scored %>%
  filter(set == "test") %>%
  mutate(pred_cut = ifelse(Score > 519, 0,1)) %>% 
  select(GB, pred_cut, Score, everything())

cm <- confusionMatrix(data = as.factor(test_scored2$pred_cut), 
                reference = as.factor(test_scored2$GB))

draw_confusion_matrix(cm)
```


Confusion Matrix for adjusted test set using score cutoff
```{r}
test_scored <- test_scored %>%
  mutate(pred_cut = ifelse(Score > 519, 0,1)) %>% 
  select(GB, pred_cut, Score, everything())

cm <- confusionMatrix(data = as.factor(test_scored$pred_cut), 
                reference = as.factor(test_scored$GB))

draw_confusion_matrix(cm)
```


