test <- accepts2 %>% anti_join(train, by = "id") %>%
as.data.frame()
# remove the id column
train <- train %>%
select(-id) %>%
as.data.frame()
saveRDS(accepts2, "../data/accepts_v2.rds")
saveRDS(rejects2, "../data/rejects_v2.rds")
saveRDS(train, "../data/train.rds")
saveRDS(test, "../data/test.rds")
# accepts2 <- readRDS("../data/accepts2.rds")
# rejects2 <- readRDS("../data/rejects_v2.rds")
# train <- readRDS("../data/train.rds")
# test <- readRDS("../data/test.rds")
rejects2 <- readRDS("../data/rejects_v2.rds")
train <- readRDS("../data/train.rds")
test <- readRDS("../data/test.rds")
train$good = abs(as.numeric(train$GB) - 2)
train <- train %>% select(good, everything(), -GB)
test$good = abs(as.numeric(test$GB) - 2)
test <- test %>% select(good, everything(), -GB, -id)
# col names of numeric predictor variables
num_names <- names(train )[sapply(train, is.numeric)]
num_names <- num_names[3:length(num_names)]
# loop through each numeric col and use smbinning to bin them into categories
# only create bins if unique vales > 5, there are significant splits and
# iv value is greater than 0.1
# smbinning expcts "good variable"
result_all_sig <- list() # Creating empty list to store all results #
for(i in 1:length(num_names)){
check_res <- smbinning(df = train, y = "good", x = num_names[i])
if(check_res == "Uniques values < 5") {
print(paste0(num_names[i], " has less than 5 unq values"))
next
}
else if(check_res == "No significant splits") {
print(paste0(num_names[i], " has no sig splits"))
next
}
else if(check_res$iv < 0.1) {
print(paste0(num_names[i], " has iv less than .1"))
next
}
else {
result_all_sig[[num_names[i]]] <- check_res
print(paste0(num_names[i], " has splits created"))
}
}
#Able to pull all information within list by variable name #
#result_all_sig$AGE$ivtable
num_names
train<-  train %>% mutate(PRODUCT = str_replace_all(PRODUCT, ",", "_"),
PROF = str_replace_all(PROF, ",", "_")) %>%
mutate_at(c("PRODUCT", "PROF"), funs(as.factor(.)))
# col names of factor predictor variables
factor_names <- names(train)[sapply(train, is.factor)]
# loop through each numeric col and use smbinning to bin them into categories
# only create bins if unique vales > 5, there are significant splits and
# iv value is greater than 0.1
# smbinning expcts "good variable"
result_all_sig_factor <- list() # Creating empty list to store all results #
for(i in 1:length(factor_names)){
check_res <- smbinning.factor(df = train, y = "good", x = factor_names[i])
if(check_res == "No significant splits") {
print(paste0(factor_names[i], " has no sig splits"))
next
}
else if(check_res$iv < 0.1) {
print(paste0(factor_names[i], " has iv less than .1"))
next
}
else {
result_all_sig_factor[[factor_names[i]]] <- check_res
print(paste0(factor_names[i], " has splits created"))
}
}
table(train$CARDS)
result_all_sig_factor[[1]]
result_all_sig_factor[[2]]
result_all_sig_factor[[3]]
all2 <- bind_cols(target, mf_imp$ximp)
# combine the df with imputed values and the df with flags indicating the
# observations that were orginally missing
all2 <- bind_cols(all2, missing_flags)
all2 <- all2 %>%
mutate(# round children and pers_h to nearest integer (imputation fractions)
CHILDREN = round(CHILDREN),
PERS_H = round(PERS_H),
adult = PERS_H - CHILDREN, # of adults in household
cash_per_pers = CASH / PERS_H,
cash_per_adult = CASH / adult,
income_per_pers = INCOME / PERS_H,
income_per_adult = INCOME/ adult,
# if cash is zero then division by zero so just impute 1.5 (avg)
income_cash_ratio = ifelse(CASH == 0, 1.5, INCOME / CASH),
total_loans = LOANS + NMBLOAN,
CARDS = ifelse(CARDS %in% c("VISA Citibank",
"VISA mybank",
"VISA Others"), "VISA",
as.character(CARDS)),
id = row_number()) %>%
select(GB, `_freq_`, id, everything())
# treat these vars as factors because they have 3 or less unq values
all2 <- all2 %>%
mutate_at(c('NMBLOAN', 'RESID', 'adult', 'TMADD_unk', 'TMJOB1_unk',
'RESID_unk', "CARDS"), funs(as.factor(.)))
# summary of the new data set
summarize_df(all2)
# separate the data back into the rejects and accepts
accepts2 <- all2 %>% filter(!is.na(GB))
rejects2 <- all2 %>% filter(is.na(GB)) %>%
as.data.frame()
# Split into train and test sets
set.seed(888)
# train set gets random 70% of data
train <- accepts2 %>% sample_frac(size = .7)
# test set gets the ones not in train
test <- accepts2 %>% anti_join(train, by = "id") %>%
as.data.frame()
# remove the id column
train <- train %>%
select(-id) %>%
as.data.frame()
saveRDS(accepts2, "../data/accepts_v2.rds")
saveRDS(rejects2, "../data/rejects_v2.rds")
saveRDS(train, "../data/train.rds")
saveRDS(test, "../data/test.rds")
rejects2 <- readRDS("../data/rejects_v2.rds")
train <- readRDS("../data/train.rds")
test <- readRDS("../data/test.rds")
train$good = abs(as.numeric(train$GB) - 2)
train <- train %>% select(good, everything(), -GB)
test$good = abs(as.numeric(test$GB) - 2)
test <- test %>% select(good, everything(), -GB, -id)
# col names of numeric predictor variables
num_names <- names(train )[sapply(train, is.numeric)]
num_names <- num_names[3:length(num_names)]
# loop through each numeric col and use smbinning to bin them into categories
# only create bins if unique vales > 5, there are significant splits and
# iv value is greater than 0.1
# smbinning expcts "good variable"
result_all_sig <- list() # Creating empty list to store all results #
for(i in 1:length(num_names)){
check_res <- smbinning(df = train, y = "good", x = num_names[i])
if(check_res == "Uniques values < 5") {
print(paste0(num_names[i], " has less than 5 unq values"))
next
}
else if(check_res == "No significant splits") {
print(paste0(num_names[i], " has no sig splits"))
next
}
else if(check_res$iv < 0.1) {
print(paste0(num_names[i], " has iv less than .1"))
next
}
else {
result_all_sig[[num_names[i]]] <- check_res
print(paste0(num_names[i], " has splits created"))
}
}
#Able to pull all information within list by variable name #
#result_all_sig$AGE$ivtable
train<-  train %>% mutate(PRODUCT = str_replace_all(PRODUCT, ",", "_"),
PROF = str_replace_all(PROF, ",", "_")) %>%
mutate_at(c("PRODUCT", "PROF"), funs(as.factor(.)))
# col names of factor predictor variables
factor_names <- names(train)[sapply(train, is.factor)]
# loop through each numeric col and use smbinning to bin them into categories
# only create bins if unique vales > 5, there are significant splits and
# iv value is greater than 0.1
# smbinning expcts "good variable"
result_all_sig_factor <- list() # Creating empty list to store all results #
for(i in 1:length(factor_names)){
check_res <- smbinning.factor(df = train, y = "good", x = factor_names[i])
if(check_res == "No significant splits") {
print(paste0(factor_names[i], " has no sig splits"))
next
}
else if(check_res$iv < 0.1) {
print(paste0(factor_names[i], " has iv less than .1"))
next
}
else {
result_all_sig_factor[[factor_names[i]]] <- check_res
print(paste0(factor_names[i], " has splits created"))
}
}
result_all_sig_factor[[3]]
# collaspe the visa variable in data prep
table(test$CARDS)
table(train$CARDS)
library(gmodels)
library(vcd)
library(smbinning)
library(dplyr)
library(stringr)
accepts <- read.csv(file = "./credit_score_card/data/orginal/accepts.csv",
header = TRUE)
accepts$good <- abs(accepts$bad - 1)
table(accepts$good)
# Create Training and Validation #
set.seed(12345)
train_id <- sample(seq_len(nrow(accepts)), size = floor(0.75*nrow(accepts)))
train <- accepts[train_id, ]
test <- accepts[-train_id, ]
table(train$good)
table(test$good)
# Binning of Continuous Variables #
result <- smbinning(df = train, y = "good", x = "tot_income")
result$ivtable
result$cut
result$iv
num_names <- names(train)[sapply(train, is.numeric)] # Gathering the names of numeric variables in data #
result_all_sig <- list() # Creating empty list to store all results #
for(i in 1:length(num_names)){
check_res <- smbinning(df = train, y = "good", x = num_names[i])
if(check_res == "Uniques values < 5") {
next
}
else if(check_res == "No significant splits") {
next
}
else if(check_res$iv < 0.1) {
next
}
else {
result_all_sig[[num_names[i]]] <- check_res
}
}
# Generating Variables of Bins and WOE Values #
for(i in 1:length(result_all_sig)) {
train <- smbinning.gen(df = train, ivout = result_all_sig[[i]],
chrname = paste(result_all_sig[[i]]$x,
"_bin", sep = ""))
}
for (j in 1:length(result_all_sig)) {
for (i in 1:nrow(train)) {
bin_name <- paste(result_all_sig[[j]]$x, "_bin", sep = "")
bin <- substr(train[[bin_name]][i], 2, 2)
woe_name <- paste(result_all_sig[[j]]$x, "_WOE", sep = "")
if(bin == 0) {
bin <- dim(result_all_sig[[j]]$ivtable)[1] - 1
train[[woe_name]][i] <- result_all_sig[[j]]$ivtable[bin, "WoE"]
} else {
train[[woe_name]][i] <- result_all_sig[[j]]$ivtable[bin, "WoE"]
}
}
}
# Build Initial Logistic Regression #
initial_score <- glm(data = train, bad ~ tot_derog_WOE +
tot_tr_WOE +
age_oldest_tr_WOE +
tot_rev_line_WOE +
rev_util_WOE +
bureau_score_WOE +
down_pyt_WOE +
ltv_WOE,
weights = train$weight, family = "binomial")
summary(initial_score)
# Evaluate the Initial Model - Training Data #
train$pred <- initial_score$fitted.values
smbinning.metrics(dataset = train, prediction = "pred", actualclass = "bad", report = 1)
smbinning.metrics(dataset = train, prediction = "pred", actualclass = "bad", plot = "ks")
smbinning.metrics(dataset = train, prediction = "pred", actualclass = "bad", plot = "auc")
#Evaluate the Initial Model - Testing Data #
for(i in 1:length(result_all_sig)) {
test <- smbinning.gen(df = test, ivout = result_all_sig[[i]],
chrname = paste(result_all_sig[[i]]$x,
"_bin", sep = ""))
}
for (j in 1:length(result_all_sig)) {
for (i in 1:nrow(test)) {
bin_name <- paste(result_all_sig[[j]]$x, "_bin", sep = "")
bin <- substr(test[[bin_name]][i], 2, 2)
woe_name <- paste(result_all_sig[[j]]$x, "_WOE", sep = "")
if(bin == 0) {
bin <- dim(result_all_sig[[j]]$ivtable)[1] - 1
test[[woe_name]][i] <- result_all_sig[[j]]$ivtable[bin, "WoE"]
} else {
test[[woe_name]][i] <- result_all_sig[[j]]$ivtable[bin, "WoE"]
}
}
}
test$pred <- predict(initial_score, newdata=test, type='response')
smbinning.metrics(dataset = test, prediction = "pred", actualclass = "bad", report = 1)
smbinning.metrics(dataset = test, prediction = "pred", actualclass = "bad", plot = "ks")
smbinning.metrics(dataset = test, prediction = "pred", actualclass = "bad", plot = "auc")
accepts$pred <- predict(initial_score, newdata=accepts, type='response')
accepts$pred <- predict(initial_score, newdata=accepts, type='response')
# Build Initial Logistic Regression #
initial_score <- glm(data = train, bad ~
tot_tr_WOE +
age_oldest_tr_WOE +
tot_rev_line_WOE +
rev_util_WOE +
bureau_score_WOE +
down_pyt_WOE +
ltv_WOE,
weights = train$weight, family = "binomial")
summary(initial_score)
# Evaluate the Initial Model - Training Data #
train$pred <- initial_score$fitted.values
smbinning.metrics(dataset = train, prediction = "pred", actualclass = "bad", report = 1)
smbinning.metrics(dataset = train, prediction = "pred", actualclass = "bad", plot = "ks")
smbinning.metrics(dataset = train, prediction = "pred", actualclass = "bad", plot = "auc")
#Evaluate the Initial Model - Testing Data #
for(i in 1:length(result_all_sig)) {
test <- smbinning.gen(df = test, ivout = result_all_sig[[i]],
chrname = paste(result_all_sig[[i]]$x,
"_bin", sep = ""))
}
for (j in 1:length(result_all_sig)) {
for (i in 1:nrow(test)) {
bin_name <- paste(result_all_sig[[j]]$x, "_bin", sep = "")
bin <- substr(test[[bin_name]][i], 2, 2)
woe_name <- paste(result_all_sig[[j]]$x, "_WOE", sep = "")
if(bin == 0) {
bin <- dim(result_all_sig[[j]]$ivtable)[1] - 1
test[[woe_name]][i] <- result_all_sig[[j]]$ivtable[bin, "WoE"]
} else {
test[[woe_name]][i] <- result_all_sig[[j]]$ivtable[bin, "WoE"]
}
}
}
test$pred <- predict(initial_score, newdata=test, type='response')
smbinning.metrics(dataset = test, prediction = "pred", actualclass = "bad", report = 1)
smbinning.metrics(dataset = test, prediction = "pred", actualclass = "bad", plot = "ks")
smbinning.metrics(dataset = test, prediction = "pred", actualclass = "bad", plot = "auc")
accepts$pred <- predict(initial_score, newdata=accepts, type='response')
accepts
# Add Scores to Initial Model #
pdo <- 20 # points to double the odds
score <- 600
odds <- 50
fact <- pdo/log(2)
os <- score - fact*log(odds)
var_names <- names(initial_score$coefficients[-1])
for(i in var_names) {
beta <- initial_score$coefficients[i]
beta0 <- initial_score$coefficients["(Intercept)"]
nvar <- length(var_names)
WOE_var <- train[[i]]
points_name <- paste(str_sub(i, end = -4), "points", sep="")
train[[points_name]] <- -(WOE_var*(beta) + (beta0/nvar))*fact + os/nvar
}
colini <- (ncol(train)-nvar + 1)
colend <- ncol(train)
train$Score <- rowSums(train[, colini:colend])
hist(train$Score, breaks = 50, main = "Distribution of Scores", xlab = "Score")
for(i in var_names) {
beta <- initial_score$coefficients[i]
beta0 <- initial_score$coefficients["(Intercept)"]
nvar <- length(var_names)
WOE_var <- test[[i]]
points_name <- paste(str_sub(i, end = -4), "points", sep="")
test[[points_name]] <- -(WOE_var*(beta) + (beta0/nvar))*fact + os/nvar
}
colini <- (ncol(test)-nvar + 1)
colend <- ncol(test)
test$Score <- rowSums(test[, colini:colend])
accepts_scored <- rbind(train, test)
accepts_scored <- rbind(train, test %>% select(names(train)))
summary(initial_score)
# Evaluate the Initial Model - Training Data #
train$pred <- initial_score$fitted.values
smbinning.metrics(dataset = train, prediction = "pred", actualclass = "bad", report = 1)
smbinning.metrics(dataset = train, prediction = "pred", actualclass = "bad", plot = "ks")
smbinning.metrics(dataset = train, prediction = "pred", actualclass = "bad", plot = "auc")
#Evaluate the Initial Model - Testing Data #
for(i in 1:length(result_all_sig)) {
test <- smbinning.gen(df = test, ivout = result_all_sig[[i]],
chrname = paste(result_all_sig[[i]]$x,
"_bin", sep = ""))
}
for (j in 1:length(result_all_sig)) {
for (i in 1:nrow(test)) {
bin_name <- paste(result_all_sig[[j]]$x, "_bin", sep = "")
bin <- substr(test[[bin_name]][i], 2, 2)
woe_name <- paste(result_all_sig[[j]]$x, "_WOE", sep = "")
if(bin == 0) {
bin <- dim(result_all_sig[[j]]$ivtable)[1] - 1
test[[woe_name]][i] <- result_all_sig[[j]]$ivtable[bin, "WoE"]
} else {
test[[woe_name]][i] <- result_all_sig[[j]]$ivtable[bin, "WoE"]
}
}
}
test$pred <- predict(initial_score, newdata=test, type='response')
smbinning.metrics(dataset = test, prediction = "pred", actualclass = "bad", report = 1)
smbinning.metrics(dataset = test, prediction = "pred", actualclass = "bad", plot = "ks")
smbinning.metrics(dataset = test, prediction = "pred", actualclass = "bad", plot = "auc")
accepts$pred <- predict(initial_score, newdata=accepts, type='response')
test
rejects <- read.csv(file = "./credit_score_card/data/orginal/rejects.csv",
header = TRUE)
i<-1
min(rejects[[i]], na.rm = TRUE)
rejects[[i]]
# Add Scores to Initial Model #
pdo <- 20 # points to double the odds
score <- 600
odds <- 50
fact <- pdo/log(2)
os <- score - fact*log(odds)
var_names <- names(initial_score$coefficients[-1])
for(i in var_names) {
beta <- initial_score$coefficients[i]
beta0 <- initial_score$coefficients["(Intercept)"]
nvar <- length(var_names)
WOE_var <- train[[i]]
points_name <- paste(str_sub(i, end = -4), "points", sep="")
train[[points_name]] <- -(WOE_var*(beta) + (beta0/nvar))*fact + os/nvar
}
colini <- (ncol(train)-nvar + 1)
colend <- ncol(train)
train$Score <- rowSums(train[, colini:colend])
hist(train$Score, breaks = 50, main = "Distribution of Scores", xlab = "Score")
for(i in var_names) {
beta <- initial_score$coefficients[i]
beta0 <- initial_score$coefficients["(Intercept)"]
nvar <- length(var_names)
WOE_var <- test[[i]]
points_name <- paste(str_sub(i, end = -4), "points", sep="")
test[[points_name]] <- -(WOE_var*(beta) + (beta0/nvar))*fact + os/nvar
}
colini <- (ncol(test)-nvar + 1)
colend <- ncol(test)
test$Score <- rowSums(test[, colini:colend])
# Reject Inference - Load Reject Data #
rejects <- read.csv(file = "./credit_score_card/data/orginal/rejects.csv",
header = TRUE)
for(i in names(result_all_sig)) {
result_all_sig[[i]]$bands[1] <- min(rejects[[i]], na.rm = TRUE)
result_all_sig[[i]]$bands[length(result_all_sig[[i]]$bands)] <- max(rejects[[i]], na.rm = TRUE)
}
for(i in 1:length(rejects[["ltv"]])){
rejects[["ltv"]][is.na(rejects[["ltv"]])] <- floor(mean(rejects[["ltv"]], na.rm = TRUE))
}
rejects_scored <- rejects
for(i in 1:length(result_all_sig)) {
rejects_scored <- smbinning.gen(df = rejects_scored, ivout = result_all_sig[[i]], chrname = paste(result_all_sig[[i]]$x, "_bin", sep = ""))
}
for (j in 1:length(result_all_sig)) {
for (i in 1:nrow(rejects_scored)) {
bin_name <- paste(result_all_sig[[j]]$x, "_bin", sep = "")
bin <- substr(rejects_scored[[bin_name]][i], 2, 2)
woe_name <- paste(result_all_sig[[j]]$x, "_WOE", sep = "")
if(bin == 0) {
bin <- dim(result_all_sig[[j]]$ivtable)[1] - 1
rejects_scored[[woe_name]][i] <- result_all_sig[[j]]$ivtable[bin, "WoE"]
} else {
rejects_scored[[woe_name]][i] <- result_all_sig[[j]]$ivtable[bin, "WoE"]
}
}
}
pdo <- 20
score <- 600
odds <- 50
fact <- pdo/log(2)
os <- score - fact*log(odds)
var_names <- names(initial_score$coefficients[-1])
for(i in var_names) {
beta <- initial_score$coefficients[i]
beta0 <- initial_score$coefficients["(Intercept)"]
nvar <- length(var_names)
WOE_var <- rejects_scored[[i]]
points_name <- paste(str_sub(i, end = -4), "points", sep="")
rejects_scored[[points_name]] <- -(WOE_var*(beta) + (beta0/nvar))*fact + os/nvar
}
colini <- (ncol(rejects_scored)-nvar + 1)
colend <- ncol(rejects_scored)
rejects_scored$Score <- rowSums(rejects_scored[, colini:colend])
rejects_scored
# Reject Inference - Hard Cut-off #
rejects_scored$pred <- predict(initial_score, newdata=rejects_scored, type='response')
as.numeric(rejects_scored$pred > 0.0603)
rejects_scored$pred
summary(rejects_scored$pred)
accepts$weight %>% table
100/300
1000/3000
32.3*100
3230/10
100/3230
32.3*100
1*100
100/320
100/.0323
3095.975/100
1/30.95975
30*75
2250/31
100-72.58065
27.41935/(27.41935+72.58065)
75-72.58065
2.41935/75
30*25
750/31
1-24.19355
25-24.19355
90/93
3/93
10/40
6/99
33/126
31/124
.333/10.3333
.59/(.59+2.8)
10.333/(30+1+10+.333)
31/3
smbinning.metrics(dataset = test, prediction = "pred", actualclass = "bad", report = 1)
